{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7eiDWcM_MC3H"
   },
   "source": [
    "# <font color='red'>Implement SGD Classifier with Logloss and L2 regularization Using SGD without using sklearn</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yfe2NTQtLq11"
   },
   "source": [
    "**There will be some functions that start with the word \"grader\" ex: grader_weights(), grader_sigmoid(), grader_logloss() etc, you should not change those function definition.<br><br>Every Grader function has to return True.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fk5DSPCLxqT-"
   },
   "source": [
    "<font color='red'> Importing packages</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "42Et8BKIxnsp"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NpSk3WQBx7TQ"
   },
   "source": [
    "<font color='red'>Creating custom dataset</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BsMp0oWzx6dv"
   },
   "outputs": [],
   "source": [
    "# please don't change random_state\n",
    "X, y = make_classification(n_samples=50000, n_features=15, n_informative=10, n_redundant=5,\n",
    "                           n_classes=2, weights=[0.7], class_sep=0.7, random_state=15)\n",
    "# make_classification is used to create custom dataset \n",
    "# Please check this link (https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html) for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "L8W2fg1cyGdX",
    "outputId": "029d4c84-03b2-4143-a04c-34ff49c88890"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 15), (50000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x99RWCgpqNHw"
   },
   "source": [
    "<font color='red'>Splitting data into train and test </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Kh4dBfVyJMP"
   },
   "outputs": [],
   "source": [
    "#please don't change random state\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0DR_YMBsyOci",
    "outputId": "732014d9-1731-4d3f-918f-a9f5255ee149"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((37500, 15), (37500,), (12500, 15), (12500,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BW4OHswfqjHR"
   },
   "source": [
    "# <font color='red' size=5>SGD classifier</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "id": "3HpvTwDHyQQy",
    "outputId": "5729f08c-079a-4b17-bf51-f9aeb5abb13b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(eta0=0.0001, learning_rate='constant', loss='log',\n",
       "              random_state=15, verbose=2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alpha : float\n",
    "# Constant that multiplies the regularization term. \n",
    "\n",
    "# eta0 : double\n",
    "# The initial learning rate for the ‘constant’, ‘invscaling’ or ‘adaptive’ schedules.\n",
    "\n",
    "clf = linear_model.SGDClassifier(eta0=0.0001, alpha=0.0001, loss='log', random_state=15, penalty='l2', tol=1e-3, verbose=2, learning_rate='constant')\n",
    "clf\n",
    "# Please check this documentation (https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 638
    },
    "colab_type": "code",
    "id": "YYaVyQ2lyXcr",
    "outputId": "dc0bf840-b37e-4552-e513-84b64f6c64c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.77, NNZs: 15, Bias: -0.316653, T: 37500, Avg. loss: 0.455552\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.91, NNZs: 15, Bias: -0.472747, T: 75000, Avg. loss: 0.394686\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.98, NNZs: 15, Bias: -0.580082, T: 112500, Avg. loss: 0.385711\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.02, NNZs: 15, Bias: -0.658292, T: 150000, Avg. loss: 0.382083\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.04, NNZs: 15, Bias: -0.719528, T: 187500, Avg. loss: 0.380486\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.05, NNZs: 15, Bias: -0.763409, T: 225000, Avg. loss: 0.379578\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1.06, NNZs: 15, Bias: -0.795106, T: 262500, Avg. loss: 0.379150\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1.06, NNZs: 15, Bias: -0.819925, T: 300000, Avg. loss: 0.378856\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1.07, NNZs: 15, Bias: -0.837805, T: 337500, Avg. loss: 0.378585\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1.08, NNZs: 15, Bias: -0.853138, T: 375000, Avg. loss: 0.378630\n",
      "Total training time: 0.07 seconds.\n",
      "Convergence after 10 epochs took 0.07 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(eta0=0.0001, learning_rate='constant', loss='log',\n",
       "              random_state=15, verbose=2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X=X_train, y=y_train) # fitting our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "EAfkVI6GyaRO",
    "outputId": "bc88f920-6531-4106-9b4c-4dabb6d72b47"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.42336692,  0.18547565, -0.14859036,  0.34144407, -0.2081867 ,\n",
       "          0.56016579, -0.45242483, -0.09408813,  0.2092732 ,  0.18084126,\n",
       "          0.19705191,  0.00421916, -0.0796037 ,  0.33852802,  0.02266721]]),\n",
       " (1, 15),\n",
       " array([-0.8531383]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_, clf.coef_.shape, clf.intercept_\n",
    "#clf.coef_ will return the weights\n",
    "#clf.coef_.shape will return the shape of weights\n",
    "#clf.intercept_ will return the intercept term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_-CcGTKgsMrY"
   },
   "source": [
    "\n",
    "\n",
    "```\n",
    "# This is formatted as code\n",
    "```\n",
    "\n",
    "## <font color='red' size=5> Implement Logistic Regression with L2 regularization Using SGD: without using sklearn </font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W1_8bdzitDlM"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "1.  We will be giving you some functions, please write code in that functions only.\n",
    "\n",
    "2.  After every function, we will be giving you expected output, please make sure that you get that output. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zU2Y3-FQuJ3z"
   },
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "* Initialize the weight_vector and intercept term to zeros (Write your code in <font color='blue'>def initialize_weights()</font>)\n",
    "\n",
    "* Create a loss function (Write your code in <font color='blue'>def logloss()</font>) \n",
    "\n",
    " $log loss = -1*\\frac{1}{n}\\Sigma_{for each Yt,Y_{pred}}(Ytlog10(Y_{pred})+(1-Yt)log10(1-Y_{pred}))$\n",
    "- for each epoch:\n",
    "\n",
    "    - for each batch of data points in train: (keep batch size=1)\n",
    "\n",
    "        - calculate the gradient of loss function w.r.t each weight in weight vector (write your code in <font color='blue'>def gradient_dw()</font>)\n",
    "\n",
    "        $dw^{(t)} = x_n(y_n − σ((w^{(t)})^{T} x_n+b^{t}))- \\frac{λ}{N}w^{(t)})$ <br>\n",
    "\n",
    "        - Calculate the gradient of the intercept (write your code in <font color='blue'> def gradient_db()</font>) <a href='https://drive.google.com/file/d/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H/view?usp=sharing'>check this</a>\n",
    "\n",
    "           $ db^{(t)} = y_n- σ((w^{(t)})^{T} x_n+b^{t}))$\n",
    "\n",
    "        - Update weights and intercept (check the equation number 32 in the above mentioned <a href='https://drive.google.com/file/d/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H/view?usp=sharing'>pdf</a>): <br>\n",
    "        $w^{(t+1)}← w^{(t)}+α(dw^{(t)}) $<br>\n",
    "\n",
    "        $b^{(t+1)}←b^{(t)}+α(db^{(t)}) $\n",
    "    - calculate the log loss for train and test with the updated weights (you can check the python assignment 10th question)\n",
    "    - And if you wish, you can compare the previous loss and the current loss, if it is not updating, then\n",
    "        you can stop the training\n",
    "    - append this loss in the list ( this will be used to see how loss is changing for each epoch after the training is over )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZR_HgjgS_wKu"
   },
   "source": [
    "<font color='blue'>Initialize weights </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GecwYV9fsKZ9"
   },
   "outputs": [],
   "source": [
    "def initialize_weights(dim):\n",
    "    ''' In this function, we will initialize our weights and bias'''\n",
    "    #initialize the weights to zeros array of (1,dim) dimensions\n",
    "    #you use zeros_like function to initialize zero, check this link https://docs.scipy.org/doc/numpy/reference/generated/numpy.zeros_like.html\n",
    "    #initialize bias to zero\n",
    "    w = np.zeros_like(dim).reshape(1,-1)\n",
    "    b = 0\n",
    "\n",
    "    return w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A7I6uWBRsKc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w = [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "b = 0\n"
     ]
    }
   ],
   "source": [
    "dim = X_train[0] \n",
    "w,b = initialize_weights(dim)\n",
    "print('w =',(w))\n",
    "print('b =',str(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4MI5SAjP9ofN"
   },
   "source": [
    "<font color='cyan'>Grader function - 1 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pv1llH429wG5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim=X_train[0] \n",
    "w,b = initialize_weights(dim)\n",
    "def grader_weights(w,b):\n",
    "  assert((len(w[0])==len(dim)) and b==0 and np.sum(w)==0.0)\n",
    "  return True\n",
    "grader_weights(w,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QN83oMWy_5rv"
   },
   "source": [
    "<font color='blue'>Compute sigmoid </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qPv4NJuxABgs"
   },
   "source": [
    "$sigmoid(z)= 1/(1+exp(-z))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nAfmQF47_Sd6"
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    ''' In this function, we will return sigmoid of z'''\n",
    "    # compute sigmoid(z) and return\n",
    "    result = 1/(1+np.exp(-z))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9YrGDwg3Ae4m"
   },
   "source": [
    "<font color='cyan'>Grader function - 2</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P_JASp_NAfK_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_sigmoid(z):\n",
    "  val=sigmoid(z)\n",
    "  assert(val==0.8807970779778823)\n",
    "  return True\n",
    "grader_sigmoid(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gS7JXbcrBOFF"
   },
   "source": [
    "<font color='blue'> Compute loss </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lfEiS22zBVYy"
   },
   "source": [
    "$log loss = -1*\\frac{1}{n}\\Sigma_{for each Yt,Y_{pred}}(Ytlog10(Y_{pred})+(1-Yt)log10(1-Y_{pred}))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VaFDgsp3sKi6"
   },
   "outputs": [],
   "source": [
    "def logloss(y_true,y_pred):\n",
    "    '''In this function, we will compute log loss '''\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    loss = -np.sum(y_true * np.log10(y_pred) + (1 - y_true) * np.log10(1 - y_pred))/len(y_true)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zs1BTXVSClBt"
   },
   "source": [
    "<font color='cyan'>Grader function - 3 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LzttjvBFCuQ5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_logloss(true,pred):\n",
    "  loss=logloss(true,pred)\n",
    "  assert(loss==0.07644900402910389)\n",
    "  return True\n",
    "true=[1,1,0,1,0]\n",
    "pred=[0.9,0.8,0.1,0.8,0.2]\n",
    "grader_logloss(true,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tQabIadLCBAB"
   },
   "source": [
    "<font color='blue'>Compute gradient w.r.to  'w' </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YTMxiYKaCQgd"
   },
   "source": [
    "$dw^{(t)} = x_n(y_n − σ((w^{(t)})^{T} x_n+b^{t}))- \\frac{λ}{N}w^{(t)}$ <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NMVikyuFsKo5"
   },
   "outputs": [],
   "source": [
    "def gradient_dw(x,y,w,b,alpha,N):\n",
    "    '''In this function, we will compute the gardient w.r.to w '''\n",
    "    dw = (x * (y- sigmoid((w@x)+b) )) - ((alpha/N)*w)\n",
    "    return dw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RUFLNqL_GER9"
   },
   "source": [
    "<font color='cyan'>Grader function - 4 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WI3xD8ctGEnJ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_dw(x,y,w,b,alpha,N):\n",
    "  grad_dw=gradient_dw(x,y,w,b,alpha,N)\n",
    "  assert(np.sum(grad_dw)==2.613689585)\n",
    "  return True\n",
    "grad_x=np.array([-2.07864835,  3.31604252, -0.79104357, -3.87045546, -1.14783286,\n",
    "       -2.81434437, -0.86771071, -0.04073287,  0.84827878,  1.99451725,\n",
    "        3.67152472,  0.01451875,  2.01062888,  0.07373904, -5.54586092])\n",
    "grad_y=0\n",
    "grad_w,grad_b=initialize_weights(grad_x)\n",
    "alpha=0.0001\n",
    "N=len(X_train)\n",
    "grader_dw(grad_x,grad_y,grad_w,grad_b,alpha,N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LE8g84_GI62n"
   },
   "source": [
    "<font color='blue'>Compute gradient w.r.to 'b' </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fHvTYZzZJJ_N"
   },
   "source": [
    "$ db^{(t)} = y_n- σ((w^{(t)})^{T} x_n+b^{t})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0nUf2ft4EZp8"
   },
   "outputs": [],
   "source": [
    " def gradient_db(x,y,w,b):\n",
    "        '''In this function, we will compute gradient w.r.to b '''\n",
    "        db = y - sigmoid(w@x+b)\n",
    "        return db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pbcBzufVG6qk"
   },
   "source": [
    "<font color='cyan'>Grader function - 5 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TfFDKmscG5qZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_db(x,y,w,b):\n",
    "  grad_db=gradient_db(x,y,w,b)\n",
    "  assert(grad_db==-0.5)\n",
    "  return True\n",
    "grad_x=np.array([-2.07864835,  3.31604252, -0.79104357, -3.87045546, -1.14783286,\n",
    "       -2.81434437, -0.86771071, -0.04073287,  0.84827878,  1.99451725,\n",
    "        3.67152472,  0.01451875,  2.01062888,  0.07373904, -5.54586092])\n",
    "grad_y=0\n",
    "grad_w,grad_b=initialize_weights(grad_x)\n",
    "alpha=0.0001\n",
    "N=len(X_train)\n",
    "grader_db(grad_x,grad_y,grad_w,grad_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TCK0jY_EOvyU"
   },
   "source": [
    "<font color='blue'> Implementing logistic regression</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dmAdc5ejEZ25"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def train(X_train,y_train,X_test,y_test,epochs,alpha,eta0):\n",
    "    ''' In this function, we will implement logistic regression'''\n",
    "    train_loss,test_loss = [],[]\n",
    "    w,b = initialize_weights(X_train[0])\n",
    "    N = len(X_train)\n",
    "    for epoch in tqdm(range(0,epochs)):\n",
    "        for x,y in zip(X_train,y_train):\n",
    "            gradw = gradient_dw(x,y,w,b,alpha,N)\n",
    "            gradb = gradient_db(x,y,w,b)\n",
    "            w += (eta0 * gradw)\n",
    "            b += (eta0 * gradb)\n",
    "        new_train_ypred = sigmoid(np.sum(w*X_train, axis = 1)+b)\n",
    "        trainloss = logloss(y_train, new_train_ypred)\n",
    "        train_loss.append(trainloss)\n",
    "        new_test_ypred = sigmoid(np.sum(w*X_test, axis = 1)+b)\n",
    "        test_loss.append(logloss(y_test,new_test_ypred))\n",
    "        if epoch>1:\n",
    "            check = train_loss[epoch-1]-train_loss[epoch]\n",
    "            if np.abs(check)<0.0001:\n",
    "                print(check)\n",
    "                break\n",
    "    return w,b,train_loss,test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dmAdc5ejEZ25"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def train2(X_train,y_train,X_test,y_test,epochs,alpha,eta0):\n",
    "    ''' In this function, we will implement logistic regression'''\n",
    "    train_loss,test_loss = [],[]\n",
    "    w,b = initialize_weights(X_train[0])\n",
    "    N = len(X_train)\n",
    "    for epoch in tqdm(range(0,epochs)):\n",
    "        for x,y in zip(X_train,y_train):\n",
    "            gradw = gradient_dw(x,y,w,b,alpha,N)\n",
    "            gradb = gradient_db(x,y,w,b)\n",
    "            w += (eta0 * gradw)\n",
    "            b += (eta0 * gradb)\n",
    "        new_train_ypred = sigmoid(np.dot(X_train,w.T)+b)\n",
    "        trainloss = logloss(y_train, new_train_ypred)\n",
    "        train_loss.append(trainloss)\n",
    "        new_test_ypred = sigmoid(np.dot(X_test,w.T)+b)\n",
    "        test_loss.append(logloss(y_test,new_test_ypred))\n",
    "        if epoch>1:\n",
    "            check = train_loss[epoch-1]-train_loss[epoch]\n",
    "            if np.abs(check)<0.0001:\n",
    "                print(check)\n",
    "                break\n",
    "    return w,b,train_loss,test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:06<00:02,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.007707537269204e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#w,b,train_loss,test_loss = train(X_train,y_train,X_test,y_test,30,0.0001,0.0001)\n",
    "w,b,train_loss,test_loss = train(X_train,y_train,X_test,y_test,10,0.0001,0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.41804213,  0.1893292 , -0.14364395,  0.33801646, -0.20470201,\n",
       "         0.56139323, -0.44564446, -0.09306797,  0.21498269,  0.16658575,\n",
       "         0.19248334,  0.00441467, -0.07514027,  0.33859136,  0.02156312]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.8187348])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.77, NNZs: 15, Bias: -0.316653, T: 37500, Avg. loss: 0.455552\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.91, NNZs: 15, Bias: -0.472747, T: 75000, Avg. loss: 0.394686\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.98, NNZs: 15, Bias: -0.580082, T: 112500, Avg. loss: 0.385711\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.02, NNZs: 15, Bias: -0.658292, T: 150000, Avg. loss: 0.382083\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.04, NNZs: 15, Bias: -0.719528, T: 187500, Avg. loss: 0.380486\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.05, NNZs: 15, Bias: -0.763409, T: 225000, Avg. loss: 0.379578\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1.06, NNZs: 15, Bias: -0.795106, T: 262500, Avg. loss: 0.379150\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1.06, NNZs: 15, Bias: -0.819925, T: 300000, Avg. loss: 0.378856\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1.07, NNZs: 15, Bias: -0.837805, T: 337500, Avg. loss: 0.378585\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1.08, NNZs: 15, Bias: -0.853138, T: 375000, Avg. loss: 0.378630\n",
      "Total training time: 0.06 seconds.\n",
      "Convergence after 10 epochs took 0.06 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(eta0=0.0001, learning_rate='constant', loss='log',\n",
       "              random_state=15, verbose=2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = linear_model.SGDClassifier(eta0=0.0001, alpha=0.0001, loss='log', random_state=15, penalty='l2', tol=1e-3, verbose=2, learning_rate='constant')\n",
    "clf.fit(X=X_train, y=y_train) # fitting our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l4Zf_wPARlwY"
   },
   "source": [
    "<font color='red'>Goal of assignment</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l3eF_VSPSH2z"
   },
   "source": [
    "Compare your implementation and SGDClassifier's the weights and intercept, make sure they are as close as possible i.e difference should be in terms of 10^-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nx8Rs9rfEZ1R"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 5.32478821e-03,  3.85354323e-03,  4.94640750e-03,\n",
       "         -3.42760674e-03,  3.48468755e-03,  1.22744016e-03,\n",
       "          6.78036985e-03,  1.02015463e-03,  5.70949454e-03,\n",
       "         -1.42555091e-02, -4.56856697e-03,  1.95513439e-04,\n",
       "          4.46342480e-03,  6.33482932e-05, -1.10408984e-03]]),\n",
       " array([0.0344035]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# these are the results we got after we implemented sgd and found the optimal weights and intercept\n",
    "w-clf.coef_, b-clf.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "230YbSgNSUrQ"
   },
   "source": [
    "<font color='blue'>Plot epoch number vs train , test loss </font>\n",
    "\n",
    "* epoch number on X-axis\n",
    "* loss on Y-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(train_loss)\n",
    "plt.plot(test_loss)\n",
    "plt.title('Train v.s Test loss by epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train loss', 'Test loss'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FUN8puFoEZtU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9577333333333333\n",
      "0.95568\n"
     ]
    }
   ],
   "source": [
    "def pred(w,b, X):\n",
    "    N = len(X)\n",
    "    predict = []\n",
    "    for i in range(N):\n",
    "        z=np.dot(w,X[i])+b\n",
    "        if sigmoid(z) >= 0.5: # sigmoid(w,x,b) returns 1/(1+exp(-(dot(x,w)+b)))\n",
    "            predict.append(1)\n",
    "        else:\n",
    "            predict.append(0)\n",
    "    return np.array(predict)\n",
    "print(1-np.sum(y_train - pred(w,b,X_train))/len(X_train))\n",
    "print(1-np.sum(y_test  - pred(w,b,X_test))/len(X_test))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "wb_python_37",
   "language": "python",
   "name": "wb_python_37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
